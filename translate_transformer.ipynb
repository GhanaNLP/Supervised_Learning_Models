{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0725 16:41:31.037638 4515880384 file_utils.py:39] PyTorch version 1.5.1 available.\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "I0725 16:41:39.243314 4515880384 file_utils.py:55] TensorFlow version 2.0.0-beta1 available.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0725 16:41:51.703933 4515880384 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/Helsinki-NLP/opus-mt-en-tw/config.json from cache at /Users/Lawrence/.cache/torch/transformers/c535643a4ab424d32b23c1bd97160f66a083f341fb6c7d91e49e7752f5320c1f.0cc69fa4f2c01c8986ac7d5528f585178d5b3f151242081d263cf568a93d3748\n",
      "I0725 16:41:51.705368 4515880384 configuration_utils.py:300] Model config MarianConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      56999\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 56999,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 57000,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 6,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 56999,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"vocab_size\": 57000\n",
      "}\n",
      "\n",
      "I0725 16:41:51.706831 4515880384 tokenization_utils_base.py:1167] Model name 'Helsinki-NLP/opus-mt-en-tw' not found in model shortcut name list (). Assuming 'Helsinki-NLP/opus-mt-en-tw' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0725 16:41:58.498842 4515880384 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/Helsinki-NLP/opus-mt-en-tw/source.spm from cache at /Users/Lawrence/.cache/torch/transformers/e8a2ed7693ba8d69d26068226c9c725f0c2956ad0f6965ba8696f58f6148ace4.10c6603c1f96f6226ef4c095f76c94f44778a2ae5b755bae7d9636fc017520bf\n",
      "I0725 16:41:58.499706 4515880384 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/Helsinki-NLP/opus-mt-en-tw/target.spm from cache at /Users/Lawrence/.cache/torch/transformers/dfdf8704dcef3c48cbe88d234457a8f0e4cff382c45d772347529da5407d04e3.43afe31f85efe550348a58ef774d3fd8ec50edc6664d218739a8df17c4b01ac6\n",
      "I0725 16:41:58.500440 4515880384 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/Helsinki-NLP/opus-mt-en-tw/vocab.json from cache at /Users/Lawrence/.cache/torch/transformers/52eb316bd8ea2968d976ae2e63c3ee0aba8a040da87e7d8c4aed9c8e85cdd8ba.a9e9c38db9e91596b219ada35a7c4732790276681fc548b408b10a257178f3fc\n",
      "I0725 16:41:58.501745 4515880384 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/Helsinki-NLP/opus-mt-en-tw/tokenizer_config.json from cache at /Users/Lawrence/.cache/torch/transformers/76b54494a2a82131b8f474f4a8638972fc3412d05d395a503a595880de15c3c0.2c3c157f3b15cae46c19cdaecab00ae1a028771a244a625f23b82888a8fab96e\n",
      "I0725 16:41:58.504217 4515880384 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/Helsinki-NLP/opus-mt-en-tw/added_tokens.json from cache at None\n",
      "I0725 16:41:58.514630 4515880384 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/Helsinki-NLP/opus-mt-en-tw/special_tokens_map.json from cache at None\n",
      "I0725 16:41:58.521838 4515880384 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/Helsinki-NLP/opus-mt-en-tw/tokenizer.json from cache at None\n",
      "/Users/Lawrence/Library/Python/3.7/lib/python/site-packages/transformers/modeling_auto.py:798: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "I0725 16:41:59.685391 4515880384 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/Helsinki-NLP/opus-mt-en-tw/config.json from cache at /Users/Lawrence/.cache/torch/transformers/c535643a4ab424d32b23c1bd97160f66a083f341fb6c7d91e49e7752f5320c1f.0cc69fa4f2c01c8986ac7d5528f585178d5b3f151242081d263cf568a93d3748\n",
      "I0725 16:41:59.687300 4515880384 configuration_utils.py:300] Model config MarianConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      56999\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 56999,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 57000,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 6,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 56999,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"vocab_size\": 57000\n",
      "}\n",
      "\n",
      "I0725 16:42:01.481359 4515880384 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/Helsinki-NLP/opus-mt-en-tw/pytorch_model.bin from cache at /Users/Lawrence/.cache/torch/transformers/b1636e42a6b46b390e97d4f9f516e643e0cde4394a5788f940cb2043eb767652.cf45064f70e28b601b759698b446804b5824bdfa377daa70f64110e2df128243\n",
      "I0725 16:42:06.452154 4515880384 modeling_utils.py:765] All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "I0725 16:42:06.461185 4515880384 modeling_utils.py:774] All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-tw.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use MarianMTModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-tw\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"Helsinki-NLP/opus-mt-en-tw\")\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁Ɔkwan▁bɛn▁so▁na▁nneɛma▁te▁saa?\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Hello, how are things?\", return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs, max_length=40, num_beams=4, early_stopping=True)\n",
    "decoded_output = [tokenizer.convert_ids_to_tokens(int(outputs[0][i])) for i in range(len(outputs[0]))]\n",
    "decoded_output_string = \"\"\n",
    "for i in range(1,len(decoded_output)):\n",
    "    decoded_output_string=decoded_output_string+decoded_output[i]\n",
    "print(decoded_output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_word='', model=model, tokenizer=tokenizer):\n",
    "    inputs = tokenizer.encode(input_word, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_length=40, num_beams=4, early_stopping=True)\n",
    "    decoded_output = [tokenizer.convert_ids_to_tokens(int(outputs[0][i])) for i in range(len(outputs[0]))]\n",
    "    decoded_output_string = \"\"\n",
    "    for i in range(1,len(decoded_output)):\n",
    "        decoded_output_string=decoded_output_string+decoded_output[i]\n",
    "    decoded_output_string = ' '.join(decoded_output_string.strip(\"▁\").split(\"▁\"))\n",
    "    return decoded_output_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Metɔ 5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I will buy 5\", model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_fwf(\"./english_sentences/english_1.txt\", delimiter=\"\\n\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.columns = [\"English\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"Twi (Predicted)\"] = test_data.loc[:, \"English\"].apply(translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(model, open(\"./model.pkl\", 'wb'))\n",
    "pickle.dump(tokenizer, open(\"./tokenizer.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"./model.pkl\", 'rb'))\n",
    "loaded_tokenizer = pickle.load(open(\"./tokenizer.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Metɔ 5'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I will buy 5\", loaded_model, loaded_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The firemen battered down the door.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom is happier now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's not a watch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let's check the map.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did you notice any change?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tom smiled at the waitress.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tom can't refuse his grandchildren anything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Do you want to be a bartender all your life?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Every day Mary took baskets full of bread to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tom destroyed the children's sand castle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>It's already 7 o'clock.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Queen lives in Buckingham Palace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I spent the entire weekend in the library stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Where should I put my laundry?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>They're ready.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The library is in the middle of the city.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I'd like to pay later.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Are you looking for someone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>You have a message.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Did you remember to turn off the gas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>It has some bearing on this problem.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tom has many powerful friends.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>My father isn't at home.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Tom had a drug problem.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I have a good mind to study abroad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Is there something you'd like to tell Tom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Would you like to go out with me tonight?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Tom often helps me with my homework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I prefer working alone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>It wasn't Tom who lit the campfire.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165160</th>\n",
       "      <td>We played together every day when we were kids.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165161</th>\n",
       "      <td>Thank you for listening to me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165162</th>\n",
       "      <td>Something terrible has happened.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165163</th>\n",
       "      <td>The ship is not equipped with radar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165164</th>\n",
       "      <td>Tom doesn't ever say \"hi\" to his neighbors.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165165</th>\n",
       "      <td>Tom wants to talk with you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165166</th>\n",
       "      <td>How do you know all these things?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165167</th>\n",
       "      <td>Tom is troubled by what happened.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165168</th>\n",
       "      <td>The newspaper is by your side.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165169</th>\n",
       "      <td>I don't trust this driver.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165170</th>\n",
       "      <td>It's worth a fortune.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165171</th>\n",
       "      <td>I love this company.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165172</th>\n",
       "      <td>I thought it was funny, too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165173</th>\n",
       "      <td>What are you waiting for?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165174</th>\n",
       "      <td>Is it true that Tom has a twin?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165175</th>\n",
       "      <td>I'm watching the Olympics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165176</th>\n",
       "      <td>Why are you smiling?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165177</th>\n",
       "      <td>Learn from others' mistakes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165178</th>\n",
       "      <td>Two tickets to San Diego, please.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165179</th>\n",
       "      <td>He was killed in a car accident.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165180</th>\n",
       "      <td>Tom wondered how many times he'd have to tell ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165181</th>\n",
       "      <td>Tom put everything back on the shelf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165182</th>\n",
       "      <td>You'll get over this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165183</th>\n",
       "      <td>Can you eat this?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165184</th>\n",
       "      <td>Who's Tom with?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165185</th>\n",
       "      <td>You're a good customer, so I'll do what I can.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165186</th>\n",
       "      <td>I plan to throw all of this away. You may take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165187</th>\n",
       "      <td>Everything's dirt-cheap.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165188</th>\n",
       "      <td>All sales are final.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165189</th>\n",
       "      <td>Tom is a hard person to please.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165190 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0                     The firemen battered down the door.\n",
       "1                                     Tom is happier now.\n",
       "2                                       It's not a watch.\n",
       "3                                    Let's check the map.\n",
       "4                              Did you notice any change?\n",
       "5                             Tom smiled at the waitress.\n",
       "6            Tom can't refuse his grandchildren anything.\n",
       "7            Do you want to be a bartender all your life?\n",
       "8       Every day Mary took baskets full of bread to t...\n",
       "9               Tom destroyed the children's sand castle.\n",
       "10                                It's already 7 o'clock.\n",
       "11                  The Queen lives in Buckingham Palace.\n",
       "12      I spent the entire weekend in the library stud...\n",
       "13                         Where should I put my laundry?\n",
       "14                                         They're ready.\n",
       "15              The library is in the middle of the city.\n",
       "16                                 I'd like to pay later.\n",
       "17                           Are you looking for someone?\n",
       "18                                    You have a message.\n",
       "19                  Did you remember to turn off the gas?\n",
       "20                   It has some bearing on this problem.\n",
       "21                         Tom has many powerful friends.\n",
       "22                               My father isn't at home.\n",
       "23                                Tom had a drug problem.\n",
       "24                    I have a good mind to study abroad.\n",
       "25             Is there something you'd like to tell Tom?\n",
       "26              Would you like to go out with me tonight?\n",
       "27                   Tom often helps me with my homework.\n",
       "28                                I prefer working alone.\n",
       "29                    It wasn't Tom who lit the campfire.\n",
       "...                                                   ...\n",
       "165160    We played together every day when we were kids.\n",
       "165161                     Thank you for listening to me.\n",
       "165162                   Something terrible has happened.\n",
       "165163               The ship is not equipped with radar.\n",
       "165164        Tom doesn't ever say \"hi\" to his neighbors.\n",
       "165165                        Tom wants to talk with you.\n",
       "165166                  How do you know all these things?\n",
       "165167                  Tom is troubled by what happened.\n",
       "165168                     The newspaper is by your side.\n",
       "165169                         I don't trust this driver.\n",
       "165170                              It's worth a fortune.\n",
       "165171                               I love this company.\n",
       "165172                       I thought it was funny, too.\n",
       "165173                          What are you waiting for?\n",
       "165174                    Is it true that Tom has a twin?\n",
       "165175                         I'm watching the Olympics.\n",
       "165176                               Why are you smiling?\n",
       "165177                       Learn from others' mistakes.\n",
       "165178                  Two tickets to San Diego, please.\n",
       "165179                   He was killed in a car accident.\n",
       "165180  Tom wondered how many times he'd have to tell ...\n",
       "165181              Tom put everything back on the shelf.\n",
       "165182                              You'll get over this.\n",
       "165183                                  Can you eat this?\n",
       "165184                                    Who's Tom with?\n",
       "165185     You're a good customer, so I'll do what I can.\n",
       "165186  I plan to throw all of this away. You may take...\n",
       "165187                           Everything's dirt-cheap.\n",
       "165188                               All sales are final.\n",
       "165189                    Tom is a hard person to please.\n",
       "\n",
       "[165190 rows x 1 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
